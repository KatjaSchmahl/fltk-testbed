{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/envs/qpe/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboard tensorflow pandas\n",
    "\n",
    "\"\"\"\n",
    "If tensorboard is not installed (or other dependencies, such as tensorflow and pandas),\n",
    "uncomment the command in top and re-run. This needs only to be run once in a Jupyter kernel.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "from collections.abc import MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard dev upload --logdir \\\n",
    "    '../logging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Change the LOG_DIR argument to point to the correct directory, you may want to use an\n",
    "absolute path if you run into issues.\n",
    "\"\"\"\n",
    "# !!kill 22140\n",
    "%tensorboard --logdir ./logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def logs_to_pandas(path: str) -> pd.DataFrame:\n",
    "    \"\"\"convert single tensorflow log file to pandas DataFrame\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to tensorflow log file\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        converted dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    runlog_data = pd.DataFrame({\"metric\": [], \"value\": [], \"step\": [], \"wall_time\": []})\n",
    "    try:\n",
    "        event_acc = summary_iterator(path)\n",
    "        for event in list(event_acc)[1:]:\n",
    "            step, wall_time = event.step, pd.to_datetime(event.wall_time, unit='s')\n",
    "            simple_extractor = [{\"metric\": v.tag, \"value\": v.simple_value, \"step\": step, 'wall_time': wall_time} for v in event.summary.value]\n",
    "            event_r = pd.DataFrame(simple_extractor)\n",
    "            runlog_data = pd.concat([runlog_data, event_r])\n",
    "    #Dirty catch of DataLossError\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "        print(\"Event file possibly corrupt: {}\".format(path))\n",
    "        print(e)\n",
    "    return runlog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting log results..\n",
      "\n",
      "getting output..  \n",
      "WARNING:tensorflow:From /home/chris/anaconda3/envs/qpe/lib/python3.10/site-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      " finished creating log dictionary: DICT_LOG_RESULTS\n"
     ]
    }
   ],
   "source": [
    "print(\"collecting log results..\")\n",
    "# creates dictionary: <id, event log dataframe>\n",
    "dict_log_results = {}\n",
    "logs = subprocess.getoutput(f'kubectl get pods -n test -l \"app.kubernetes.io/name=fltk.extractor\" -o jsonpath=\"{{.items[0].metadata.name}}\"')\n",
    "print(subprocess.getoutput(\"rm -rf logging\"))\n",
    "print(\"getting output.. \", subprocess.getoutput(f\"kubectl cp -n test {logs}:logging ./logging\"))\n",
    "for path in Path('./logging').rglob('*events.out*'):\n",
    "    path_iid = path.name.split(\"trainjob-\")[1].split(\"-master\")[0]\n",
    "    dict_log_results[path_iid] = logs_to_pandas(f\"./{path}\")\n",
    "    \n",
    "print(\"\\n finished creating log dictionary: DICT_LOG_RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: './logging/configmaps'\n",
      "collecting 20 configmaps ..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "fetched! caching..\n",
      "finished collecting configmaps, see DICT_LOG_RESULTS\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(d: MutableMapping, sep: str= '.') -> MutableMapping:\n",
    "    [flat_dict] = pd.json_normalize(d, sep=sep).to_dict(orient='records')\n",
    "    return flat_dict\n",
    "\n",
    "try: \n",
    "    os.mkdir(\"./logging/configmaps\") \n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    \n",
    "def job_to_id(job_name: str):\n",
    "    return job_name.split(\"master-\")[1][:-2]\n",
    "\n",
    "job_ids = [i for i in subprocess.getoutput(\"kubectl get configmap --all-namespaces\").split(\" \") if \"master\" in i]\n",
    "job_ids = [j for j in job_ids if job_to_id(j) in dict_log_results.keys()] # union with log results\n",
    "      \n",
    "print(f\"collecting {len(job_ids)} configmaps ..\")\n",
    "dict_configmaps =  {}\n",
    "for j in job_ids:\n",
    "    try:\n",
    "        # fetching from cloud and saving in logging/configmaps/-id-.txt\n",
    "        config_map = subprocess.getoutput(f\"kubectl get configmaps {j} -o yaml -n test\")\n",
    "        text_file = open(f\"./logging/configmaps/{j}.txt\", \"w\")\n",
    "        n = text_file.write(config_map)\n",
    "        text_file.close()\n",
    "        print(\"fetched! caching..\")\n",
    "    except Exception as e:\n",
    "        # in case of error (e.g. not in cloud), fetch from cache\n",
    "        print(\"error, finding in cache.. \")\n",
    "        with open(f\"./logging/configmaps/{j}.txt\", 'r') as file:\n",
    "            config_map = file.read().replace('\\n', '')\n",
    "        \n",
    "    dict_configmaps[job_to_id(j)] = flatten_dict(yaml.safe_load(yaml.safe_load(config_map)['data']['node.config.yaml']))\n",
    "    \n",
    "print(\"finished collecting configmaps, see DICT_LOG_RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('seed', 539797574)}\n",
      "{('seed', 698416725)}\n",
      "{('seed', 1977273656)}\n",
      "{('seed', 1977273656)}\n",
      "{('seed', 391183769)}\n",
      "{('seed', 2469606724)}\n",
      "{('seed', 4006973926)}\n",
      "{('seed', 4006973926)}\n",
      "{('seed', 3828286053)}\n",
      "{('seed', 3393082523)}\n",
      "{('seed', 3393082523)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['11dc762c-0781-45f6-b16f-8f0b739493e4',\n",
       "   '505a1dd5-09ae-46ad-8d82-039016c0c1bb'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0              0.003              100   539797574         100   \n",
       "  0              0.003              100   539797574         100   \n",
       "  0              0.003              100   539797574         100   \n",
       "  0              0.003              100  4283453153         100   \n",
       "  0              0.003              100  4283453153         100   \n",
       "  0              0.003              100  4283453153         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  0                  180           2         2          0.003      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  11dc762c-0781-45f6-b16f-8f0b739493e4       accuracy per epoch   \n",
       "  0  11dc762c-0781-45f6-b16f-8f0b739493e4        training duration   \n",
       "  0  11dc762c-0781-45f6-b16f-8f0b739493e4  training loss per epoch   \n",
       "  0  505a1dd5-09ae-46ad-8d82-039016c0c1bb  training loss per epoch   \n",
       "  0  505a1dd5-09ae-46ad-8d82-039016c0c1bb       accuracy per epoch   \n",
       "  0  505a1dd5-09ae-46ad-8d82-039016c0c1bb        training duration   \n",
       "  \n",
       "             value  step                     wall_time  \n",
       "  0      87.940002   4.0 2022-10-18 10:20:50.285159168  \n",
       "  0  166666.000000   4.0 2022-10-18 10:20:50.285210112  \n",
       "  0       0.250383   5.0 2022-10-18 10:21:38.480099072  \n",
       "  0       0.272853   4.0 2022-10-18 09:16:20.889095936  \n",
       "  0      88.580002   4.0 2022-10-18 09:16:20.889224192  \n",
       "  0  203764.000000   4.0 2022-10-18 09:16:20.889278976  ),\n",
       " (['1b44d70e-937a-4f0f-96df-878be3a6ac2d',\n",
       "   '2a5ac654-eea9-4b56-b67d-347950653f32'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0              0.003              100   698416725         100   \n",
       "  0              0.003              100   698416725         100   \n",
       "  0              0.003              100   698416725         100   \n",
       "  0              0.003              100  3264073673         100   \n",
       "  0              0.003              100  3264073673         100   \n",
       "  0              0.003              100  3264073673         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  0                 1800           2         2          0.003      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  1b44d70e-937a-4f0f-96df-878be3a6ac2d  training loss per epoch   \n",
       "  0  1b44d70e-937a-4f0f-96df-878be3a6ac2d       accuracy per epoch   \n",
       "  0  1b44d70e-937a-4f0f-96df-878be3a6ac2d        training duration   \n",
       "  0  2a5ac654-eea9-4b56-b67d-347950653f32  training loss per epoch   \n",
       "  0  2a5ac654-eea9-4b56-b67d-347950653f32       accuracy per epoch   \n",
       "  0  2a5ac654-eea9-4b56-b67d-347950653f32        training duration   \n",
       "  \n",
       "            value  step                     wall_time  \n",
       "  0  6.198325e-02  44.0 2022-10-18 10:53:34.543629312  \n",
       "  0  8.882000e+01  44.0 2022-10-18 10:53:34.543749376  \n",
       "  0  1.827616e+06  44.0 2022-10-18 10:53:34.543790592  \n",
       "  0  7.089959e-02  35.0 2022-10-18 11:27:57.246799360  \n",
       "  0  8.864000e+01  35.0 2022-10-18 11:27:57.246942208  \n",
       "  0  1.834847e+06  35.0 2022-10-18 11:27:57.246987520  ),\n",
       " (['537a1c1e-cf76-466b-a9c6-07359039b8ae',\n",
       "   '638228e6-e81b-4697-9a09-d53f4f94791f',\n",
       "   '7a11f838-fa7d-4307-a942-e9b89804d2f5'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0             0.0005              100  1977273656         100   \n",
       "  0             0.0005              100  1977273656         100   \n",
       "  0             0.0005              100  1977273656         100   \n",
       "  0             0.0005              100   268000807         100   \n",
       "  0             0.0005              100   268000807         100   \n",
       "  0             0.0005              100   268000807         100   \n",
       "  0             0.0005              100  1012895187         100   \n",
       "  0             0.0005              100  1012895187         100   \n",
       "  0             0.0005              100  1012895187         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  0                 1800           2         2         0.0005      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  537a1c1e-cf76-466b-a9c6-07359039b8ae  training loss per epoch   \n",
       "  0  537a1c1e-cf76-466b-a9c6-07359039b8ae       accuracy per epoch   \n",
       "  0  537a1c1e-cf76-466b-a9c6-07359039b8ae        training duration   \n",
       "  0  638228e6-e81b-4697-9a09-d53f4f94791f  training loss per epoch   \n",
       "  0  638228e6-e81b-4697-9a09-d53f4f94791f       accuracy per epoch   \n",
       "  0  638228e6-e81b-4697-9a09-d53f4f94791f        training duration   \n",
       "  0  7a11f838-fa7d-4307-a942-e9b89804d2f5  training loss per epoch   \n",
       "  0  7a11f838-fa7d-4307-a942-e9b89804d2f5       accuracy per epoch   \n",
       "  0  7a11f838-fa7d-4307-a942-e9b89804d2f5        training duration   \n",
       "  \n",
       "            value  step                     wall_time  \n",
       "  0  4.486403e-02  35.0 2022-10-18 09:43:30.208436736  \n",
       "  0  8.966000e+01  35.0 2022-10-18 09:43:30.208602112  \n",
       "  0  1.832995e+06  35.0 2022-10-18 09:43:30.208666880  \n",
       "  0  4.069164e-02  35.0 2022-10-18 09:43:03.003528192  \n",
       "  0  8.884000e+01  35.0 2022-10-18 09:43:03.003648768  \n",
       "  0  1.804964e+06  35.0 2022-10-18 09:43:03.003691520  \n",
       "  0  4.075418e-02  44.0 2022-10-18 10:52:00.966332928  \n",
       "  0  8.898000e+01  44.0 2022-10-18 10:52:00.966455552  \n",
       "  0  1.802425e+06  44.0 2022-10-18 10:52:00.966494976  ),\n",
       " (['5adddfd9-efa8-4805-9f4d-ec8d4cbd29e9',\n",
       "   '895fd3fd-fa2a-48f9-84eb-a4edb158fe51'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0              0.003              100   391183769         100   \n",
       "  0              0.003              100   391183769         100   \n",
       "  0              0.003              100   391183769         100   \n",
       "  0              0.003              100  1282726241         100   \n",
       "  0              0.003              100  1282726241         100   \n",
       "  0              0.003              100  1282726241         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  0                  180           0         2          0.003      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  5adddfd9-efa8-4805-9f4d-ec8d4cbd29e9  training loss per epoch   \n",
       "  0  5adddfd9-efa8-4805-9f4d-ec8d4cbd29e9       accuracy per epoch   \n",
       "  0  5adddfd9-efa8-4805-9f4d-ec8d4cbd29e9        training duration   \n",
       "  0  895fd3fd-fa2a-48f9-84eb-a4edb158fe51  training loss per epoch   \n",
       "  0  895fd3fd-fa2a-48f9-84eb-a4edb158fe51       accuracy per epoch   \n",
       "  0  895fd3fd-fa2a-48f9-84eb-a4edb158fe51        training duration   \n",
       "  \n",
       "             value  step                     wall_time  \n",
       "  0       0.225265   6.0 2022-10-18 09:50:33.133405696  \n",
       "  0      87.980003   6.0 2022-10-18 09:50:33.133517056  \n",
       "  0  185620.000000   6.0 2022-10-18 09:50:33.133556224  \n",
       "  0       0.226877   6.0 2022-10-18 09:24:23.063656192  \n",
       "  0      88.239998   6.0 2022-10-18 09:24:23.063767296  \n",
       "  0  183764.000000   6.0 2022-10-18 09:24:23.063797248  ),\n",
       " (['68466821-7502-4980-920b-660fb4392609',\n",
       "   'd9ee4dc1-dcbe-4edd-a481-6bd595b52005'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0             0.0005              100  2469606724         100   \n",
       "  0             0.0005              100  2469606724         100   \n",
       "  0             0.0005              100  2469606724         100   \n",
       "  0             0.0005              100  1927556850         100   \n",
       "  0             0.0005              100  1927556850         100   \n",
       "  0             0.0005              100  1927556850         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  0                 1800           0         2         0.0005      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  68466821-7502-4980-920b-660fb4392609  training loss per epoch   \n",
       "  0  68466821-7502-4980-920b-660fb4392609       accuracy per epoch   \n",
       "  0  68466821-7502-4980-920b-660fb4392609        training duration   \n",
       "  0  d9ee4dc1-dcbe-4edd-a481-6bd595b52005  training loss per epoch   \n",
       "  0  d9ee4dc1-dcbe-4edd-a481-6bd595b52005       accuracy per epoch   \n",
       "  0  d9ee4dc1-dcbe-4edd-a481-6bd595b52005        training duration   \n",
       "  \n",
       "            value  step                     wall_time  \n",
       "  0  3.080294e-02  52.0 2022-10-18 09:15:29.082958848  \n",
       "  0  8.848000e+01  52.0 2022-10-18 09:15:29.083090944  \n",
       "  0  1.815536e+06  52.0 2022-10-18 09:15:29.083148288  \n",
       "  0  5.980641e-02  50.0 2022-10-18 11:22:50.471855104  \n",
       "  0  8.796000e+01  50.0 2022-10-18 11:22:50.471962368  \n",
       "  0  1.831952e+06  50.0 2022-10-18 11:22:50.472000256  ),\n",
       " (['6eb661de-57b9-4c98-a392-0a7cf7754699',\n",
       "   '7762bb53-f1e7-4709-b225-12fae6387f56',\n",
       "   'cab94add-e61e-4e4a-a14e-8cbb014e3b9e'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0             0.0005              100  4006973926         100   \n",
       "  0             0.0005              100  4006973926         100   \n",
       "  0             0.0005              100  4006973926         100   \n",
       "  0             0.0005              100  3027769029         100   \n",
       "  0             0.0005              100  3027769029         100   \n",
       "  0             0.0005              100  3027769029         100   \n",
       "  0             0.0005              100  2651810783         100   \n",
       "  0             0.0005              100  2651810783         100   \n",
       "  0             0.0005              100  2651810783         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  0                  180           0         2         0.0005      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  6eb661de-57b9-4c98-a392-0a7cf7754699        training duration   \n",
       "  0  6eb661de-57b9-4c98-a392-0a7cf7754699  training loss per epoch   \n",
       "  0  6eb661de-57b9-4c98-a392-0a7cf7754699       accuracy per epoch   \n",
       "  0  7762bb53-f1e7-4709-b225-12fae6387f56       accuracy per epoch   \n",
       "  0  7762bb53-f1e7-4709-b225-12fae6387f56        training duration   \n",
       "  0  7762bb53-f1e7-4709-b225-12fae6387f56  training loss per epoch   \n",
       "  0  cab94add-e61e-4e4a-a14e-8cbb014e3b9e  training loss per epoch   \n",
       "  0  cab94add-e61e-4e4a-a14e-8cbb014e3b9e       accuracy per epoch   \n",
       "  0  cab94add-e61e-4e4a-a14e-8cbb014e3b9e        training duration   \n",
       "  \n",
       "             value  step                     wall_time  \n",
       "  0  164664.000000   4.0 2022-10-18 08:46:09.672016640  \n",
       "  0       0.240083   5.0 2022-10-18 08:46:50.566355712  \n",
       "  0      89.040001   5.0 2022-10-18 08:46:50.566489088  \n",
       "  0      89.260002   6.0 2022-10-18 10:56:41.841685760  \n",
       "  0  176888.000000   6.0 2022-10-18 10:56:41.841740800  \n",
       "  0       0.207376   7.0 2022-10-18 10:57:11.563012608  \n",
       "  0       0.230846   5.0 2022-10-18 10:22:53.076844544  \n",
       "  0      88.720001   5.0 2022-10-18 10:22:53.076947200  \n",
       "  0  188160.000000   5.0 2022-10-18 10:22:53.076977920  ),\n",
       " (['92d59931-d09c-4e53-9bd4-e0522605c42f',\n",
       "   'c22cacdd-bedd-4190-b7f9-5d45db276b38'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0             0.0005              100  3828286053         100   \n",
       "  0             0.0005              100  3828286053         100   \n",
       "  0             0.0005              100  3828286053         100   \n",
       "  0             0.0005              100  1441191704         100   \n",
       "  0             0.0005              100  1441191704         100   \n",
       "  0             0.0005              100  1441191704         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  0                  180           2         2         0.0005      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  92d59931-d09c-4e53-9bd4-e0522605c42f       accuracy per epoch   \n",
       "  0  92d59931-d09c-4e53-9bd4-e0522605c42f        training duration   \n",
       "  0  92d59931-d09c-4e53-9bd4-e0522605c42f  training loss per epoch   \n",
       "  0  c22cacdd-bedd-4190-b7f9-5d45db276b38  training loss per epoch   \n",
       "  0  c22cacdd-bedd-4190-b7f9-5d45db276b38       accuracy per epoch   \n",
       "  0  c22cacdd-bedd-4190-b7f9-5d45db276b38        training duration   \n",
       "  \n",
       "             value  step                     wall_time  \n",
       "  0      88.080002   4.0 2022-10-18 09:46:30.698576128  \n",
       "  0  155390.000000   4.0 2022-10-18 09:46:30.698608384  \n",
       "  0       0.240856   5.0 2022-10-18 09:47:10.274583552  \n",
       "  0       0.253600   4.0 2022-10-18 10:57:20.266831872  \n",
       "  0      88.279999   4.0 2022-10-18 10:57:20.266941952  \n",
       "  0  202712.000000   4.0 2022-10-18 10:57:20.266972928  ),\n",
       " (['b1fcdb8a-5caf-432f-87e0-a685e1c63fdc',\n",
       "   'e44b3db4-27fd-4fd5-a357-a904f4f5943b',\n",
       "   'f0484fab-2555-46fd-8574-5b60a6bffd29'],\n",
       "     optimizer_args.lr  test_batch_size        seed  batch_size  \\\n",
       "  0              0.003              100  3393082523         100   \n",
       "  0              0.003              100  3393082523         100   \n",
       "  0              0.003              100  3393082523         100   \n",
       "  0              0.003              100  2218779736         100   \n",
       "  0              0.003              100  2218779736         100   \n",
       "  0              0.003              100  2218779736         100   \n",
       "  0              0.003              100  3604134194         100   \n",
       "  0              0.003              100  3604134194         100   \n",
       "  0              0.003              100  3604134194         100   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  0                 1800           0         2          0.003      Adam   \n",
       "  \n",
       "                                   exp_id                   metric  \\\n",
       "  0  b1fcdb8a-5caf-432f-87e0-a685e1c63fdc       accuracy per epoch   \n",
       "  0  b1fcdb8a-5caf-432f-87e0-a685e1c63fdc        training duration   \n",
       "  0  b1fcdb8a-5caf-432f-87e0-a685e1c63fdc  training loss per epoch   \n",
       "  0  e44b3db4-27fd-4fd5-a357-a904f4f5943b  training loss per epoch   \n",
       "  0  e44b3db4-27fd-4fd5-a357-a904f4f5943b       accuracy per epoch   \n",
       "  0  e44b3db4-27fd-4fd5-a357-a904f4f5943b        training duration   \n",
       "  0  f0484fab-2555-46fd-8574-5b60a6bffd29  training loss per epoch   \n",
       "  0  f0484fab-2555-46fd-8574-5b60a6bffd29       accuracy per epoch   \n",
       "  0  f0484fab-2555-46fd-8574-5b60a6bffd29        training duration   \n",
       "  \n",
       "            value  step                     wall_time  \n",
       "  0  8.812000e+01  60.0 2022-10-18 10:17:10.501047040  \n",
       "  0  1.777332e+06  60.0 2022-10-18 10:17:10.501077504  \n",
       "  0  2.278637e-02  61.0 2022-10-18 10:17:41.997279232  \n",
       "  0  2.838501e-02  52.0 2022-10-18 11:27:59.500090624  \n",
       "  0  8.860000e+01  52.0 2022-10-18 11:27:59.500200960  \n",
       "  0  1.827085e+06  52.0 2022-10-18 11:27:59.500230656  \n",
       "  0  2.335002e-02  64.0 2022-10-18 10:52:04.902087424  \n",
       "  0  8.834000e+01  64.0 2022-10-18 10:52:04.902188032  \n",
       "  0  1.818472e+06  64.0 2022-10-18 10:52:04.902217728  ),\n",
       " (['c3d1773f-2c4b-4285-b65b-76d0efeb21b6'],\n",
       "     optimizer_args.lr  test_batch_size       seed  batch_size  \\\n",
       "  0                  2              128  989893139         128   \n",
       "  0                  2              128  989893139         128   \n",
       "  0                  2              128  989893139         128   \n",
       "  \n",
       "     service_time_budget  model_size  parallel  learning_rate optimizer  \\\n",
       "  0                  300           2         4              2       SGD   \n",
       "  0                  300           2         4              2       SGD   \n",
       "  0                  300           2         4              2       SGD   \n",
       "  \n",
       "                                   exp_id                   metric     value  \\\n",
       "  0  c3d1773f-2c4b-4285-b65b-76d0efeb21b6  training loss per epoch       NaN   \n",
       "  0  c3d1773f-2c4b-4285-b65b-76d0efeb21b6       accuracy per epoch      10.8   \n",
       "  0  c3d1773f-2c4b-4285-b65b-76d0efeb21b6        training duration  322299.0   \n",
       "  \n",
       "     step                     wall_time  \n",
       "  0  13.0 2022-10-18 07:57:10.937825280  \n",
       "  0  13.0 2022-10-18 07:57:10.937965056  \n",
       "  0  13.0 2022-10-18 07:57:10.938014208  )]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Creating clusters ---\n",
    "experiments = [(idd, set(value.items())) for idd, value in dict_configmaps.items()]\n",
    "clusters = []\n",
    "diff_attr_total = set() # set of total different attr values found between experiments\n",
    "while len(experiments) > 0:\n",
    "    next_exp = experiments[0]\n",
    "    cluster = list([next_exp])\n",
    "    for e in experiments[1:]:\n",
    "        diff_attr = next_exp[1].difference(e[1])\n",
    "        diff_attr_total = diff_attr_total.union(set([s[0] for s in diff_attr]))\n",
    "        if len(diff_attr) <= 1:\n",
    "            print(next_exp[1].difference(e[1])) # should only be seed difference!!!\n",
    "            cluster.append(e)\n",
    "    for e in cluster:\n",
    "        experiments.remove(e)\n",
    "    clusters.append(cluster)\n",
    "\n",
    "# --- Combining dataframes of clusters ---\n",
    "cluster_ids = [[e[0] for e in exp_l] for exp_l in clusters]\n",
    "id_archieved_metric = {}\n",
    "for k,v in dict_log_results.items():\n",
    "    df = v.drop_duplicates('metric', keep='last')\n",
    "    df.insert(0, 'exp_id', k)\n",
    "    for attr in diff_attr_total:\n",
    "        df.insert(0, attr, dict_configmaps[k][attr])\n",
    "    id_archieved_metric[k] = df\n",
    "\n",
    "cluster_to_metrics = [(ids, pd.concat([id_archieved_metric[i] for i in ids])) for ids in cluster_ids]\n",
    "\n",
    "cluster_to_metrics\n",
    "# diff_attr_total\n",
    "\n",
    "# dict_configmaps\n",
    "# cluster_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qpe] *",
   "language": "python",
   "name": "conda-env-qpe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
